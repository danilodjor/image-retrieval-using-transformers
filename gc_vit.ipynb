{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "\n",
    "from timm.layers import SelectAdaptivePool2d\n",
    "from torch.nn import Flatten\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itet-stor/ddordevic/net_scratch/conda_envs/mscenv/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /croot/pytorch_1675190298929/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model('gcvit_base.in1k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_layer = SelectAdaptivePool2d(pool_type='avg', flatten=Flatten(start_dim=1, end_dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_transform = timm.data.create_transform(\n",
    "    **timm.data.resolve_data_config(model.pretrained_cfg)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1 # was 8\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../datasets/CIFAR-10', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../datasets/CIFAR-10', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder setup\n",
    "train_features_file = \"training_cifar10.pkl\"\n",
    "test_features_file = \"test_cifar10.pkl\"\n",
    "features_folder = \"./CIFAR-10/\"\n",
    "train_features_path = features_folder + train_features_file\n",
    "test_features_path = features_folder + test_features_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6757, 0.8793, 0.3450, 0.5754]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_pickle(train_features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6757274 , 0.879346  , 0.34496897, 0.57538706]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for img, lab in train_loader:\n",
    "    img = transforms.ToPILImage()(img[0])\n",
    "    img = gc_transform(img).unsqueeze(0)\n",
    "    print(img.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vit_b_16, vit_b_32, swin_b#, swin_v2_b\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\"\"\" \n",
    "Extracts the features of the images in the CIFAR-10 dataset using the pre-trained vision transformers.\n",
    "This way the database of CIFAR-10 images becomes a database of CIFAR-10 transformer feature representations.\n",
    "Python notebook is used to test the code before running it fully as a pure Python script. \n",
    "\n",
    "Steps:\n",
    "    1. Load the trained transformer model\n",
    "    2. Strip off the final classification layer\n",
    "    3. Go through images and forward propagate them\n",
    "    4. For each image save the final transformer layer representation of that image.\n",
    "\"\"\"\n",
    "\n",
    "# Models & transforms (used for feature extraction with pre-trained models) setup\n",
    "gc_model = timm.create_model('gcvit_base.in1k', pretrained=True)\n",
    "gc_model.eval()\n",
    "\n",
    "gc_pool_layer = SelectAdaptivePool2d(pool_type='avg', flatten=Flatten(start_dim=1, end_dim=-1))\n",
    "gc_transform = timm.data.create_transform(\n",
    "    **timm.data.resolve_data_config(model.pretrained_cfg)\n",
    ")\n",
    "\n",
    "\n",
    "models = ['gc_vit_b']\n",
    "\n",
    "# Folder setup\n",
    "train_features_file = \"training_cifar10.pkl\"\n",
    "test_features_file = \"test_cifar10.pkl\"\n",
    "features_folder = \"./CIFAR-10/\"\n",
    "train_features_path = features_folder + train_features_file\n",
    "test_features_path = features_folder + test_features_file\n",
    "\n",
    "# Dataset setup\n",
    "batch_size = 1 # was 8\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../datasets/CIFAR-10', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../datasets/CIFAR-10', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "train_len = len(train_loader) # number of batches\n",
    "test_len = len(test_loader)\n",
    "\n",
    "\n",
    "# Main loop\n",
    "def main():\n",
    "    # Check that folders exist \n",
    "    if not os.path.exists(features_folder):\n",
    "        raise Exception(\"Extracted features folder does not exist.\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "    \n",
    "    gc_model = gc_model.to(device)\n",
    "\n",
    "    # TRAINING: Initial dataframe\n",
    "    if not os.path.exists(train_features_path):\n",
    "        print('Initial train database save file in progress...')\n",
    "\n",
    "        training_df = pd.DataFrame(columns=['image','label'])\n",
    "\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            images, labels = batch\n",
    "            images = np.array(images)\n",
    "            labels = np.array(labels)\n",
    "            new_rows = pd.DataFrame({'image': tuple(images), 'label':  tuple(labels)})\n",
    "            training_df = pd.concat([training_df, new_rows], ignore_index=True)\n",
    "            if i%99 == 0:\n",
    "                print(f\"{i+1}/{len(train_loader)}\")\n",
    "\n",
    "        training_df.to_pickle(train_features_path)\n",
    "\n",
    "        print('Initial train database save file done.')\n",
    "    else:\n",
    "        print(f'Reading existing initial training features file')\n",
    "        training_df = pd.read_pickle(train_features_path)\n",
    "\n",
    "    # TEST: Initial dataframe\n",
    "    if not os.path.exists(test_features_path):\n",
    "        print('Initial test database save file in progress...')\n",
    "\n",
    "        test_df = pd.DataFrame(columns=['image','label'])\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            images, labels = batch\n",
    "            images = np.array(images)\n",
    "            labels = np.array(labels)\n",
    "            new_rows = pd.DataFrame({'image': tuple(images), 'label':  tuple(labels)})\n",
    "            test_df = pd.concat([test_df, new_rows], ignore_index=True)\n",
    "            if i%99 == 0:\n",
    "                print(f\"{i+1}/{len(test_loader)}\")\n",
    "        test_df.to_pickle(test_features_path)\n",
    "        \n",
    "        print('Initial test database save file done.')\n",
    "    else:\n",
    "        print(f'Reading existing {test_features_file}')\n",
    "        test_df = pd.read_pickle(test_features_path)\n",
    "\n",
    "    # FEATURE EXTRACTION USING GC-VIT\n",
    "    num_train_imgs = len(training_df)\n",
    "    num_test_imgs = len(test_df)\n",
    "\n",
    "    for model_name in models:\n",
    "        print('-----------------------------')\n",
    "        print(f'Current model = {model_name}')\n",
    "\n",
    "        if (model_name in training_df.columns) and (model_name in test_df.columns):\n",
    "            continue\n",
    "\n",
    "        if model_name.startswith('swin'): # swin has different layer nomenclature\n",
    "            num_features = model.head.in_features\n",
    "            model.head = torch.nn.Identity()\n",
    "        elif model_name.startswith('vit'): # all ViTs have the same layer nomenclature\n",
    "            num_features = model.heads[0].in_features\n",
    "            model.heads = torch.nn.Identity()\n",
    "\n",
    "        # Main feature extraction loop\n",
    "        with torch.no_grad():\n",
    "            # Feature extraction loop: Training set\n",
    "            print(f'TRAINING SET EXTRACTION ({model_name}): ')\n",
    "            model_features = np.zeros((num_train_imgs, num_features))\n",
    "            for i in range(0, len(training_df), batch_size):\n",
    "                images = np.stack(training_df.iloc[i:i+batch_size]['image'])\n",
    "\n",
    "                images = transforms.ToPILImage()(images[0])\n",
    "                images = gc_transform(images).unsqueeze(0)\n",
    "                images = images.to(device)\n",
    "                \n",
    "                model_features[i:i+batch_size] = np.array(pool_layer(gc_model.forward_features(images)).cpu())\n",
    "                if i % 99 == 0:\n",
    "                    print(f\"{i+1}/{num_train_imgs}\")\n",
    "\n",
    "            training_df[model_name] = tuple(model_features)\n",
    "\n",
    "            # Feature extraction loop: Test set\n",
    "            print(f'TEST SET EXTRACTION ({model_name}): ')\n",
    "            model_features = np.zeros((num_test_imgs, num_features))\n",
    "            for i in range(0, len(test_df), batch_size):\n",
    "                images = np.stack(test_df.iloc[i:i+batch_size]['image'])\n",
    "\n",
    "                images = transforms.ToPILImage()(images[0])\n",
    "                images = gc_transform(images).unsqueeze(0)\n",
    "                images = images.to(device)\n",
    "                \n",
    "                model_features[i:i+batch_size] = np.array(model(images).cpu())\n",
    "                if i % 99 == 0:\n",
    "                    print(f\"{i+1}/{num_test_imgs}\")\n",
    "\n",
    "            test_df[model_name] = tuple(model_features)\n",
    "\n",
    "    # Saving the dataframes with extracted features\n",
    "    training_df.to_pickle(train_features_path)\n",
    "    test_df.to_pickle(test_features_path)\n",
    "\n",
    "    print('#'*50 + '\\n')\n",
    "    print('Successfully saved the dataframes containing extracted features in pickle files.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
