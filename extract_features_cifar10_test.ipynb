{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itet-stor/ddordevic/net_scratch/conda_envs/mscenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vit_b_16, vit_b_32#, vit_l_16, vit_l_32, vit_h_14\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\"\"\" \n",
    "Extracts the features of the images in the MNIST dataset using the trained vision transformer.\n",
    "This way the database of MNIST images becomes a database of MNIST trasnformer feature representations.\n",
    "Python notebook is used to test the code before running it fully as a pure Python script. \n",
    "\n",
    "Steps:\n",
    "    1. Load the trained transformer model\n",
    "    2. Strip off the final classification layer\n",
    "    3. Go through images and forward propagate them\n",
    "    4. For each image save the final transformer layer representation of that image.\n",
    "\"\"\"\n",
    "\n",
    "run_on_server = True\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "models = {\"vit_b_16\": vit_b_16, \"vit_b_32\": vit_b_32}\n",
    "weights = {\"vit_b_16\": torchvision.models.ViT_B_16_Weights.IMAGENET1K_V1,\\\n",
    "           \"vit_b_32\": torchvision.models.ViT_B_32_Weights.IMAGENET1K_V1}\n",
    "\n",
    "train_features_file = \"training_cifar10.pkl\"\n",
    "test_features_file = \"test_cifar10.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Don't change\n",
    "if run_on_server:\n",
    "    features_folder = \"/usr/itetnas04/data-scratch-01/ddordevic/data/cluster_scripts/vit_copy/CIFAR-10/\"\n",
    "else:\n",
    "    features_folder = \"C:/Users/danil/Desktop/Master thesis/Code/msc-thesis/CIFAR-10/\"\n",
    "\n",
    "train_features_path = features_folder + train_features_file\n",
    "test_features_path = features_folder + test_features_file\n",
    "\n",
    "# Dataset preparation\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../datasets/CIFAR-10', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../datasets/CIFAR-10', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "train_len = len(train_loader) # number of batches\n",
    "test_len = len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cpu \n",
      "Initial train database save file in progress.\n",
      "0/6250\n",
      "99/6250\n",
      "198/6250\n",
      "297/6250\n",
      "396/6250\n",
      "495/6250\n",
      "594/6250\n",
      "693/6250\n",
      "792/6250\n",
      "891/6250\n",
      "990/6250\n",
      "1089/6250\n",
      "1188/6250\n",
      "1287/6250\n",
      "1386/6250\n",
      "1485/6250\n",
      "1584/6250\n",
      "1683/6250\n",
      "1782/6250\n",
      "1881/6250\n",
      "1980/6250\n",
      "2079/6250\n",
      "2178/6250\n",
      "2277/6250\n",
      "2376/6250\n",
      "2475/6250\n",
      "2574/6250\n",
      "2673/6250\n",
      "2772/6250\n",
      "2871/6250\n",
      "2970/6250\n",
      "3069/6250\n",
      "3168/6250\n",
      "3267/6250\n",
      "3366/6250\n",
      "3465/6250\n",
      "3564/6250\n",
      "3663/6250\n",
      "3762/6250\n",
      "3861/6250\n",
      "3960/6250\n",
      "4059/6250\n",
      "4158/6250\n",
      "4257/6250\n",
      "4356/6250\n",
      "4455/6250\n",
      "4554/6250\n",
      "4653/6250\n",
      "4752/6250\n",
      "4851/6250\n",
      "4950/6250\n",
      "5049/6250\n",
      "5148/6250\n",
      "5247/6250\n",
      "5346/6250\n",
      "5445/6250\n",
      "5544/6250\n",
      "5643/6250\n",
      "5742/6250\n",
      "5841/6250\n",
      "5940/6250\n",
      "6039/6250\n",
      "6138/6250\n",
      "6237/6250\n",
      "Initial train database save file done.\n",
      "Initial test database save file in progress.\n",
      "0/1250\n",
      "99/1250\n",
      "198/1250\n",
      "297/1250\n",
      "396/1250\n",
      "495/1250\n",
      "594/1250\n",
      "693/1250\n",
      "792/1250\n",
      "891/1250\n",
      "990/1250\n",
      "1089/1250\n",
      "1188/1250\n",
      "Initial test database save file done.\n"
     ]
    }
   ],
   "source": [
    "# Check that folders exist \n",
    "if not os.path.exists(features_folder):\n",
    "    raise Exception(\"Extracted features folder does not exist.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "\n",
    "# TRAINING\n",
    "if not os.path.exists(train_features_path):\n",
    "    training_df = pd.DataFrame(columns=['image','label'])\n",
    "\n",
    "    print('Initial train database save file in progress.')\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        images, labels = batch\n",
    "        new_rows = pd.DataFrame({'image': tuple(images), 'label':  tuple(labels)})\n",
    "        training_df = pd.concat([training_df, new_rows], ignore_index=True)\n",
    "        if i%99 == 0:\n",
    "            print(f\"{i}/{len(train_loader)}\")\n",
    "\n",
    "    training_df.to_pickle(train_features_path)\n",
    "\n",
    "    print('Initial train database save file done.')\n",
    "else:\n",
    "    print(f'Reading existing {train_features_file}')\n",
    "    training_df = pd.read_pickle(train_features_path)\n",
    "\n",
    "# TEST\n",
    "if not os.path.exists(test_features_path):\n",
    "    print('Initial test database save file in progress.')\n",
    "\n",
    "    test_df = pd.DataFrame(columns=['image','label'])\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        images, labels = batch\n",
    "        new_rows = pd.DataFrame({'image': tuple(images), 'label':  tuple(labels)})\n",
    "        test_df = pd.concat([test_df, new_rows], ignore_index=True)\n",
    "        if i%99 == 0:\n",
    "            print(f\"{i}/{len(test_loader)}\")\n",
    "    test_df.to_pickle(test_features_path)\n",
    "    \n",
    "    print('Initial test database save file done.')\n",
    "else:\n",
    "    print(f'Reading existing {test_features_file}')\n",
    "    test_df = pd.read_pickle(test_features_path)\n",
    "\n",
    "# Iterate over the models to be used (key is model)\n",
    "num_train_imgs = len(training_df)\n",
    "num_test_imgs = len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key = vit_b_16\n"
     ]
    }
   ],
   "source": [
    "for key in models.keys():\n",
    "    print(f'Key = {key}')\n",
    "\n",
    "    model_weights = weights[key]\n",
    "    model_transform = model_weights.transforms()\n",
    "    model = models[key](weights = model_weights)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = model.heads[0].in_features\n",
    "model_features = torch.zeros(num_train_imgs, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df[\"vit_b_32\"] = tuple(model_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/itetnas04/data-scratch-01/ddordevic/data/cluster_scripts/vit_copy/CIFAR-10/training_cifar10.pkl'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_df \u001b[39m=\u001b[39m training_df\u001b[39m.\u001b[39;49mto_pickle(\u001b[39m'\u001b[39;49m\u001b[39m/usr/itetnas04/data-scratch-01/ddordevic/data/cluster_scripts/vit_copy/CIFAR-10/training_cifar10_proba.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/itet-stor/ddordevic/net_scratch/conda_envs/mscenv/lib/python3.10/site-packages/pandas/core/generic.py:3064\u001b[0m, in \u001b[0;36mNDFrame.to_pickle\u001b[0;34m(self, path, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3013\u001b[0m \u001b[39mPickle (serialize) object to file.\u001b[39;00m\n\u001b[1;32m   3014\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3060\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[1;32m   3061\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[1;32m   3062\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpickle\u001b[39;00m \u001b[39mimport\u001b[39;00m to_pickle\n\u001b[0;32m-> 3064\u001b[0m to_pickle(\n\u001b[1;32m   3065\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3066\u001b[0m     path,\n\u001b[1;32m   3067\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3068\u001b[0m     protocol\u001b[39m=\u001b[39;49mprotocol,\n\u001b[1;32m   3069\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3070\u001b[0m )\n",
      "File \u001b[0;32m/itet-stor/ddordevic/net_scratch/conda_envs/mscenv/lib/python3.10/site-packages/pandas/io/pickle.py:112\u001b[0m, in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m    109\u001b[0m     handles\u001b[39m.\u001b[39mhandle\u001b[39m.\u001b[39mwrite(pickle\u001b[39m.\u001b[39mdumps(obj, protocol\u001b[39m=\u001b[39mprotocol))\n\u001b[1;32m    110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     \u001b[39m# letting pickle write directly to the buffer is more memory-efficient\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     pickle\u001b[39m.\u001b[39;49mdump(obj, handles\u001b[39m.\u001b[39;49mhandle, protocol\u001b[39m=\u001b[39;49mprotocol)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'mscenv (Python 3.10.10)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "training_df = training_df.to_pickle('/usr/itetnas04/data-scratch-01/ddordevic/data/cluster_scripts/vit_copy/CIFAR-10/training_cifar10_proba.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key = vit_b_16\n",
      "TRAINING (vit_b_16): \n",
      "0\n",
      "TEST (vit_b_16): \n",
      "0\n",
      "Key = vit_b_32\n",
      "TRAINING (vit_b_32): \n",
      "0\n",
      "TEST (vit_b_32): \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for key in models.keys():\n",
    "    print(f'Key = {key}')\n",
    "\n",
    "    model_weights = weights[key]\n",
    "    model_transform = model_weights.transforms()\n",
    "    model = models[key](weights = model_weights)\n",
    "\n",
    "    num_features = model.heads[0].in_features\n",
    "\n",
    "    model.heads = torch.nn.Identity()\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    # Main feature extraction loop\n",
    "    with torch.no_grad():\n",
    "        # Feature extraction loop: Training set\n",
    "        print(f'TRAINING ({key}): ')\n",
    "\n",
    "        model_features = torch.zeros(num_train_imgs, num_features, requires_grad=False)\n",
    "        \n",
    "        for i in range(0, len(training_df), batch_size):\n",
    "            images = torch.stack(tuple(training_df.iloc[i:i+batch_size]['image']))\n",
    "            images = images.to(device)\n",
    "            model_features[i:i+batch_size] = model(model_transform(images))\n",
    "            print(i)\n",
    "            break\n",
    "            if i % 99 == 0:\n",
    "                print(f\"{i+1}/{num_train_imgs}\")\n",
    "\n",
    "        training_df[key] = tuple(model_features)\n",
    "\n",
    "        # Feature extraction loop: Test set\n",
    "        print(f'TEST ({key}): ')\n",
    "        model_features = torch.zeros(num_test_imgs, num_features)\n",
    "        for i in range(0, len(test_df), batch_size):\n",
    "            images = torch.stack(tuple(test_df.iloc[i:i+batch_size]['image']))\n",
    "            images = images.to(device)\n",
    "            model_features[i:i+batch_size] = model(model_transform(images))\n",
    "            print(i)\n",
    "            break\n",
    "            if i % 99 == 0:\n",
    "                print(f\"{i+1}/{num_test_imgs}\")\n",
    "\n",
    "        test_df[key] = tuple(model_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],[7,8,9]])\n",
    "b = torch.tensor([4,5,6])\n",
    "\n",
    "a[1] = b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0] = 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
